[meta]
save_dir = "experiments"
description = "This is a description of FullSubNet experiment."
seed = 0  # set random seed for random, numpy, pytorch-gpu and pytorch-cpu
keep_reproducibility = false  # see https://pytorch.org/docs/stable/notes/randomness.html
use_amp = false  # use automatic mixed precision, it will benefits Tensor Core-enabled GPU (e.g. Volta, Turing, Ampere). 2-3X speedupã€‚

[acoustic]
sr = 16000
n_fft = 510
win_length = 510
hop_length = 255
power = 0.3

[train_dataset]
path = "dataset.DNS_INTERSPEECH_train_stft_dataloader.DatasetSTFT"
[train_dataset.args]
clean_dataset = "/media/administrator/736be68f-3ad2-4ea3-8ebf-c2e3983b05c9/Data/DNS-Challenge/datasets/clean"
clean_dataset_limit = false
clean_dataset_offset = 0
noise_dataset = "/media/administrator/736be68f-3ad2-4ea3-8ebf-c2e3983b05c9/Data/DNS-Challenge/datasets/noise"
noise_dataset_limit = false
noise_dataset_offset = 0
rir_dataset = "/media/administrator/736be68f-3ad2-4ea3-8ebf-c2e3983b05c9/Data/DNS-Challenge/datasets/impulse_responses"
rir_dataset_limit = false
rir_dataset_offset = 0
snr_range = [-5, 20]
reverb_proportion = 0.75
silence_length = 0.2
target_dB_FS = -25
target_dB_FS_floating_value = 10
sub_sample_length = 2.0399375
sr = 16000
pre_load_clean_dataset = false
pre_load_noise = false
pre_load_rir = false
num_workers = 36
n_fft = 510
win_length = 510
hop_length = 255

[train_dataset.dataloader]
batch_size = 1
num_workers = 10
shuffle = true
pin_memory = true
drop_last = true

[validation_dataset]
path = "dataset.DNS_INTERSPEECH_validation.Dataset"
[validation_dataset.args]
#dataset_dir_list = "/home/administrator/Data/DNS-Challenge/dataset/raw_data/test_set/synthetic/no_reverb/audio/noisy"
dataset_dir_list = ["/home/administrator/Data/DNS-Challenge/datasets/test_set/synthetic/no_reverb/audio/",
                    "/home/administrator/Data/DNS-Challenge/datasets/test_set/synthetic/with_reverb/audio/"]
sr = 16000
sub_sample_length = 2.0399375

[model]
path = "src.model.pvt_se_model.Model"
[model.args]
pe_depth = 10
#look_ahead = 2

[model.backbone]
path = "src.model.module.pvt.PyramidVisionTransformer"
[model.backbone.args]
spec_size = [256, 128]
patch_size = 4
in_chans = 12
embed_dims = [64, 128, 320, 512]
num_heads = [1, 2, 5, 8]
mlp_ratios = [8, 8, 4, 4]
qkv_bias = true
depths = [3, 4, 18, 3]
sr_ratios = [8, 4, 2, 1]

[model.neck]
path = "src.model.module.fpn.FPN"
[model.neck.args]
in_channels = [64, 128, 320, 512]
out_channels = 256
num_outs = 4
start_level = 0
end_level = -1
add_extra_convs = false
extra_convs_on_inputs = false
relu_before_extra_convs = false
no_norm_on_lateral = false
[model.neck.args.upsample_cfg]
mode='nearest'
[model.neck.args.act_cfg]
type='PReLU'
[model.neck.args.norm_cfg]
type='BN'

[model.head]
path = "src.model.module.fpn_head.FPNHead"
[model.head.args]
spec_size = [256, 128]
feature_strides = [4, 8, 16, 32]
in_channels = [256, 256, 256, 256]
channels = 128
num_classes = 2
align_corners = false
[model.head.args.act_cfg]
type='PReLU'
[model.head.args.norm_cfg]
type='BN'



[loss_function]
path = "model.loss.mse_loss"
reduction='mean'

[optimizer]
lr = 6e-3
beta1 = 0.9
beta2 = 0.999
weight_decay = 0

[trainer]
path = "trainer.pvt_se_trainer.Trainer"
[trainer.train]
epochs = 9999
save_checkpoint_interval = 10
clip_grad_norm_value = 5
[trainer.validation]
validation_interval = 5
save_max_metric_score = true
[trainer.visualization]
n_samples = 10
num_workers = 36
metrics = ["WB_PESQ", "NB_PESQ", "STOI", "SI_SDR"]
